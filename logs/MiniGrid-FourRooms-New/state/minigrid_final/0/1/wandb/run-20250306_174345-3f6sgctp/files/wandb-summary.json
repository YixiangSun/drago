{"train/episode": 1501, "_timestamp": 1741342350.0436208, "train/step": 300000, "train/env_step": 300000, "train/total_time": 41278.99096918106, "train/episode_reward": 244.6862631610726, "train/reviewer_episode_reward": 2.0400538444519043, "train/old_model_episode_reward": 48.90761184692383, "train/learner_model_episode_cost": 93.73521423339844, "eval/episode": 1501, "eval/step": 300000, "eval/env_step": 300000, "eval/total_time": 41278.99096918106, "eval/episode_reward": 245.9951297914244, "eval/reviewer_episode_reward": 2.0400538444519043, "eval/old_model_episode_reward": 48.90761184692383, "eval/learner_model_episode_cost": 93.73521423339844, "_runtime": 41324.40321493149, "_step": 300000, "train/learner_consistency_loss": 0.0, "train/learner_reward_loss": 0.6650422215461731, "train/learner_value_loss": 78.26702880859375, "train/learner_pi_loss": -117.56488037109375, "train/learner_total_loss": 8.159224510192871, "train/learner_weighted_loss": 2.957716703414917, "train/learner_grad_norm": 2.1851160526275635, "train/learner_mean_prediction_score": 0.0, "train/vae_recon_loss": 0.014203878119587898, "train/vae_kl_loss": 0.052259188145399094, "train/vae_loss": 0.06646306812763214, "train/vae_grad_norm": 0.15619096159934998, "train/reviewer_consistency_loss": 0.0009481896995566785, "train/reviewer_reward_loss": 0.018852978944778442, "train/reviewer_value_loss": 1.5720711946487427, "train/reviewer_pi_loss": 9.437349319458008, "train/reviewer_total_loss": 0.16852998733520508, "train/reviewer_weighted_loss": 0.08152011781930923, "train/reviewer_grad_norm": 0.0792306438088417, "train/reviewer_mean_prediction_score": 7.7314276695251465, "_wandb": {"runtime": 41323}}